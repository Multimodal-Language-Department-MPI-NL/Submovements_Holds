# Submovements and Holds

> Attribution: Use the script prepared for the focus group session. Attribute to this Envision Box module: [Module](https://www.envisionbox.org/embedded_MergingMultimodal_inPython.html)

Detect holds and submovements from MediaPipe keypoint time series and summarize gesture pauses.

## ğŸ”¬ Research Context

This module shows how to calculate the number of submovements of a movement signal based on peak speed and detect movement holds (i.e., pauses) below a certain speed threshold. These measures relate to how complex and/or segmented a movement signal is.

## ğŸ¯ What This Project Does

1. **Load keypoints**: Read body landmark time series
2. **Convert to OpenPose-like format**: Map selected MediaPipe landmarks to expected keys
3. **Detect submovements**: Peak picking on smoothed hand velocity traces
4. **Detect holds**: Identify low-velocity clusters and compute durations
5. **Batch processing**: Optionally compute measures across multiple files

## ğŸ“Š Smoothing Process

1. **Begin with Cleaned Data**: Use processed time series with `time` and landmark coordinates
2. **Convert Coordinates**: Build OpenPose-like columns (e.g., `L_Hand`, `R_Hand`, `Neck`, `MidHip`)
3. **Tune Parameters**: Interactively set `height`, `prominence`, `distance` for peak detection
4. **Compute Metrics**: Submovement counts; number of holds, total/average hold duration
5. **Export**: Save per-file summaries to CSV

## ğŸ”§ Smoothing Techniques

- **Velocity estimation**: Frame-to-frame displacement Ã— FPS
- **Smoothing**: Savitzkyâ€“Golay on velocity before peak picking
- **Peak detection**: `scipy.signal.find_peaks` with `height`, `prominence`, `distance`
- **Hold detection**: Velocity thresholding and clustering into contiguous segments

## ğŸ“ Project Structure

```
Submovements_Holds/
â”œâ”€â”€ README.md
â”œâ”€â”€ environment.yml
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01-gesture_hold_time_pauses.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ timeseries/                 # Input CSVs
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ segments/                       # Output event segments (optional)
â”‚   â””â”€â”€ figures/
â”‚       â””â”€â”€ diagram.png
â””â”€â”€ scripts/
    â””â”€â”€ detect_holds.py                 # (If used)
```

## ğŸš€ Quick Start

### Prerequisites

```bash
conda env create -f environment.yml
conda activate submovements
```

### Run the Interactive Notebook

```bash
jupyter lab
# Open notebooks/01-gesture_hold_time_pauses.ipynb
```


## ğŸ“ˆ Data Format

### Input
- **CSV files**: Landmark coordinates per frame; include `time` if available

### Output
- **CSV summaries**: Per-file metrics (e.g., `num_holds`, `avg_hold_duration`)
- **Interactive figures**: Peak locations, hold intervals overlaid on velocity

## ğŸ”— Related Projects

- `https://github.com/Multimodal-Language-Department-MPI-NL/Smoothing`
- `https://github.com/Multimodal-Language-Department-MPI-NL/Normalization`
- `https://github.com/Multimodal-Language-Department-MPI-NL/Speed_Acceleration_Jerk`

## ğŸ“– References

- **Attribution**: Envision Box Module
- `scipy.signal.find_peaks` documentation